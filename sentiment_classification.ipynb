{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\purva31\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 1)) (2.4.1)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\purva31\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\purva31\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 3)) (4.66.5)\n",
      "Requirement already satisfied: typing in c:\\users\\purva31\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from -r requirements.txt (line 4)) (3.7.4.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\purva31\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\purva31\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\purva31\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (1.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\purva31\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\purva31\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\purva31\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\purva31\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (72.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\purva31\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->-r requirements.txt (line 3)) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\purva31\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\purva31\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classification Dataset \n",
    "\n",
    "The training data consists of a collection of short hotel reviews. The data is formatted as one review per line. Each line starts with a unique identifier for the review (as in ID-2001) followed by tab and the text of the review.  The reviews are not tokenized or sentence segmented in any way (the words are space separated). The positive reviews and negative reviews appear in separate files namely [hotelPosT-train.txt](data/hotelPosT-train.txt) and [hotelNegT-train.txt](data/hotelNegT-train.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "\n",
    "def load_train_data(positive_filepath, negative_filepath):\n",
    "    def _read(filename):\n",
    "        texts = []\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                _id, text = line.rstrip().split(\"\\t\")\n",
    "                texts.append(text)\n",
    "        return texts\n",
    "\n",
    "    texts = []\n",
    "    labels = []\n",
    "\n",
    "    for text in _read(positive_filepath):\n",
    "        texts.append(text)\n",
    "        labels.append(1)\n",
    "\n",
    "    for text in _read(negative_filepath):\n",
    "        texts.append(text)\n",
    "        labels.append(0)\n",
    "\n",
    "    return texts, labels\n",
    "\n",
    "\n",
    "pos_datapath = \"data/hotelPosT-train.txt\"\n",
    "neg_datapath = \"data/hotelNegT-train.txt\"\n",
    "all_texts, all_labels = load_train_data(pos_datapath, neg_datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at what is in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Positive Example ---\n",
      "Once you book a room at the Baltimore Hyatt Regency Hotel, you will get an instant feeling of being right at home. The hotel staff greets all of it's customers with warm smiles and candy. The hotel staff, upon request, can give you a tour of the room that you plan to book. Once you are in your hotel room, the rooms are emmaculate. Overlooking the Inner Harbor and all of it's attractions. I was able to visit the attractions, have dinner in the hotel's dining room, and kick back and enjoy the room.\n",
      "\n",
      "--- Negative Example ---\n",
      "Upon check in at the hotel the front desk person was very rude, and attenitive in the least. The room was dirty, and the jaccuzi was filthy and out dated.\n"
     ]
    }
   ],
   "source": [
    "# printing positive and negative examples from all_texts\n",
    "def random_sample(texts, labels, label):\n",
    "    data_by_label = {}\n",
    "    for lab, text in zip(labels, texts):\n",
    "        if lab not in data_by_label:\n",
    "            data_by_label[lab] = []\n",
    "        data_by_label[lab].append(text)\n",
    "    return random.choice(data_by_label[label])\n",
    "\n",
    "print(\"--- Positive Example ---\")\n",
    "print(random_sample(all_texts, all_labels, label=1))\n",
    "print(\"\\n--- Negative Example ---\")\n",
    "print(random_sample(all_texts, all_labels, label=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the test data\n",
    "\n",
    "def load_test_data(filepath):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    label_mapping = {'POS': 1, 'NEG': 0}  \n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            idx, text, label = line.rstrip().split(\"\\t\")\n",
    "            texts.append(text)\n",
    "            labels.append(label_mapping[label])  \n",
    "    return texts, labels\n",
    "\n",
    "# Example usage\n",
    "test_datapath = \"data/testset.txt\"\n",
    "test_texts, test_labels = load_test_data(test_datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing the number of \"positive\" and \"negative\" samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the List of Labels:  189\n",
      "Number of positive labels(1):  95\n",
      "Number of negative labels(0):  94\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(95, 94)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_distribution(labels):\n",
    "    ar = np.array(labels)\n",
    "    pos_count = np.count_nonzero(ar == 1)\n",
    "    neg_count = ar.size - pos_count\n",
    "    print(\"Size of the List of Labels: \",ar.size)\n",
    "    print(\"Number of positive labels(1): \",pos_count)\n",
    "    print(\"Number of negative labels(0): \", neg_count)\n",
    "    \"\"\"\n",
    "    TODO: Replace the line `raise NotImplementedError` with your code\n",
    "    to print the labels distribution.\n",
    "\n",
    "    Args:\n",
    "        labels (List[int]): Labels for the dataset. 1 = postive, 0 = negative\n",
    "    \n",
    "    Returns\n",
    "        pos_count, neg_count (int, int): The counts of each label\n",
    "    \"\"\"\n",
    "    return pos_count, neg_count\n",
    "\n",
    "\n",
    "label_distribution(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Training and Development Sets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of coming with the best parameters for the model we will have to split the dataset into training and development sets. Make sure the splits follow the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Label Distribution:\n",
      "Size of the List of Labels:  152\n",
      "Number of positive labels(1):  80\n",
      "Number of negative labels(0):  72\n",
      "Dev Label Distribution:\n",
      "Size of the List of Labels:  37\n",
      "Number of positive labels(1):  15\n",
      "Number of negative labels(0):  22\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15, 22)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_dataset(texts, labels):\n",
    "    X, y = np.array(texts), np.array(labels)\n",
    "    n_samples = X.shape[0]\n",
    "    indices = np.random.permutation(n_samples)\n",
    "    test_set_size = int(n_samples * 0.2)\n",
    "    test_indices = indices[:test_set_size]\n",
    "    train_indices = indices[test_set_size:]\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "    \"\"\"\n",
    "    Split the dataset randomly into 80% training and 20% development set\n",
    "    Make sure the splits have the same label distribution\n",
    "    \"\"\"\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "train_texts, train_labels, dev_texts, dev_labels = split_dataset(all_texts, all_labels)\n",
    "\n",
    "print('Train Label Distribution:')\n",
    "label_distribution(train_labels)\n",
    "\n",
    "print('Dev Label Distribution:')\n",
    "label_distribution(dev_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics\n",
    "\n",
    "Implementing the evaulation metrics: Accuracy, Precision, Recall and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted_labels, true_labels):\n",
    "    correct = sum([1 for true,pred in zip(true_labels,predicted_labels) if true==pred])\n",
    "    total = len(true_labels)\n",
    "    \"\"\"\n",
    "    Accuracy is correct predictions / all predicitons\n",
    "    \"\"\"\n",
    "    \n",
    "    return correct/total\n",
    "\n",
    "def precision(predicted_labels, true_labels):\n",
    "    true_positive = sum([1 for true, pred in zip(true_labels, predicted_labels) if true == pred == 1])\n",
    "    false_positive = sum([1 for true, pred in zip(true_labels, predicted_labels) if true == 0 and pred == 1])\n",
    "    if (true_positive + false_positive) == 0:\n",
    "        return 0\n",
    "    \"\"\"\n",
    "    Precision is True Positives / All Positives Predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    return true_positive / (true_positive + false_positive)\n",
    "\n",
    "def recall(predicted_labels, true_labels):\n",
    "    true_positive = sum([1 for true, pred in zip(true_labels, predicted_labels) if true == pred == 1])\n",
    "    false_negative = sum([1 for true, pred in zip(true_labels, predicted_labels) if true == 1 and pred == 0])\n",
    "    \n",
    "    if (true_positive + false_negative) == 0:\n",
    "        return 0\n",
    "    \"\"\"\n",
    "    Recall is True Positives / All Positive Labels\n",
    "    \"\"\"\n",
    "    \n",
    "    return true_positive / (true_positive + false_negative)\n",
    "\n",
    "def f1_score(predicted_labels, true_labels):\n",
    "    prec = precision(true_labels, predicted_labels)\n",
    "    rec = recall(true_labels, predicted_labels)\n",
    "    if (prec + rec) == 0:\n",
    "        return 0\n",
    "    \"\"\"\n",
    "    F1 score is the harmonic mean of precision and recall\n",
    "    \"\"\"\n",
    "    \n",
    "    return 2 * (prec * rec) / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Test Cases Passed!\n"
     ]
    }
   ],
   "source": [
    "em_test_labels = [0]*6 + [1]*4\n",
    "em_test_predictions = [0]*8 + [1]*2\n",
    "\n",
    "em_test_accuracy = 0.8\n",
    "em_test_precision = 1.0\n",
    "em_test_recall = 0.5\n",
    "em_test_f1 = 2/3\n",
    "\n",
    "assert accuracy(em_test_predictions, em_test_labels) == em_test_accuracy\n",
    "assert precision(em_test_predictions, em_test_labels) == em_test_precision \n",
    "assert recall(em_test_predictions, em_test_labels) == em_test_recall\n",
    "assert f1_score(em_test_predictions, em_test_labels) == em_test_f1\n",
    "\n",
    "print('All Test Cases Passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to come up with baselines for the classifications to compare the more complicated models with. The baselines are also useful as a debugging method for your actual classfication model. We will create two baselines:\n",
    "\n",
    "1. Random Chance\n",
    "2. Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: Random Chance Classifier\n",
    "\n",
    "A random chance classifier predicts the label according to the label's distribution. As an example, if the label 1 appears 70% of the times in the training set, you predict 70 out of 100 times the label 1 and label 0 30% of the times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_random(train_labels, num_samples):\n",
    "    \"\"\"\n",
    "    Using the label distribution, predict the label num_sample number of times\n",
    "    \"\"\"\n",
    "    label_count = np.bincount(train_labels)\n",
    "    \n",
    "    label_prob = label_count / len(train_labels)\n",
    "    return np.random.choice([0, 1], size=num_samples, p=label_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the List of Labels:  100\n",
      "Number of positive labels(1):  29\n",
      "Number of negative labels(0):  71\n",
      "Size of the List of Labels:  100\n",
      "Number of positive labels(1):  70\n",
      "Number of negative labels(0):  30\n",
      "All Test Cases Passed!\n"
     ]
    }
   ],
   "source": [
    "rc_labels = np.array([1]*10 + [0]*5, dtype=int)\n",
    "rc_predictions = predict_random(rc_labels, 3)\n",
    "assert len(rc_predictions) == 3\n",
    "assert len(set(rc_predictions).difference({0, 1})) == 0\n",
    "\n",
    "rc_labels = np.array([0]*10 + [1]*5, dtype=int)\n",
    "rc_predictions = predict_random(rc_labels, 100)\n",
    "p, n = label_distribution(rc_predictions)\n",
    "assert n > p\n",
    "\n",
    "rc_labels = np.array([1]*10 + [0]*5, dtype=int)\n",
    "rc_predictions = predict_random(rc_labels, 100)\n",
    "p, n = label_distribution(rc_predictions)\n",
    "assert p > n\n",
    "\n",
    "print('All Test Cases Passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: Naive Bayes Classifier \n",
    "\n",
    "Here we will implement a Naive Bayes Classifier using the tokens in the training sample. As a preprocessing step, we will tokenize via whitespace separation and lowercase all tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing \n",
    "\n",
    "Tokenizing text by separating by whitespace, and then lowercase all tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Test Cases Passed!\n"
     ]
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    if isinstance(text, str):\n",
    "        # If text is a string, split it into words and convert to lowercase\n",
    "        return [word.lower() for word in text.split()]\n",
    "    elif isinstance(text, list):\n",
    "        # If text is already a list, convert each word to lowercase\n",
    "        return [word.lower() for word in text]\n",
    "    \n",
    "test_string = \"This sentence needs to be preprocessed.\"\n",
    "\n",
    "assert preprocess(test_string) == ['this', 'sentence', 'needs', 'to', 'be', 'preprocessed.']\n",
    "\n",
    "print('All Test Cases Passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Naive Bayes Class \n",
    "\n",
    "The standard way for implementing classifiers like Naive Bayes is to implement the two methods: \"fit\" and \"predict\". \n",
    "\n",
    "The fit method expects the training data along with labels, and the predict method predicts the labels for the provides texts of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.label_word_counter = [{} for _ in range(num_classes)]\n",
    "        self.label_words_count = [0] * num_classes\n",
    "        self.vocab = set()\n",
    "    \n",
    "    def fit(self, texts, labels): \n",
    "        \"\"\"\n",
    "        1. Group samples by their labels\n",
    "        2. Preprocess each text\n",
    "        3. Count the words of the text for each label\n",
    "        \"\"\"\n",
    "        for text, label in zip(texts, labels):\n",
    "            self.label_words_count[label] += 1\n",
    "            words = preprocess(text)\n",
    "            self.vocab.update(words)\n",
    "            \n",
    "            for word in words:\n",
    "                if word not in self.label_word_counter[label]:\n",
    "                    self.label_word_counter[label][word] = 0\n",
    "                self.label_word_counter[label][word] += 1 \n",
    "                self.label_words_count[label] += 1\n",
    "    \n",
    "    def predict(self, texts):\n",
    "        \"\"\"\n",
    "        1. Preprocess the texts\n",
    "        2. Predict the class by using the likelihood with Bayes Method and Laplace Smoothing\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        vocab_size = len(self.vocab)\n",
    "        \n",
    "        for text in texts:\n",
    "            words = preprocess(text)\n",
    "            log_probs = [0] * self.num_classes\n",
    "\n",
    "            total_samples = sum(self.label_words_count)  \n",
    "            \n",
    "            for label in range(self.num_classes):\n",
    "                log_probs[label] = np.log(self.label_words_count[label] / total_samples)\n",
    "\n",
    "                \n",
    "                for word in words:\n",
    "                    word_count = self.label_word_counter[label].get(word, 0) + 1  \n",
    "                    total_words = self.label_words_count[label] + vocab_size  \n",
    "                    log_probs[label] += np.log(word_count / total_words)  \n",
    "            \n",
    "            \n",
    "            predicted_label = np.argmax(log_probs)\n",
    "            predictions.append(predicted_label)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is not hyperparameter-tuing required for the baselines, we can use the entirety of the training set (no need to split the dataset into train and development). Reporting the results achieved with the two baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Chance F1: 0.47058823529411764\n",
      "Naive Bayes F1: 0.9375\n"
     ]
    }
   ],
   "source": [
    "### DEV SET RESULTS\n",
    "\n",
    "testset_prediction_random = predict_random(train_labels, num_samples=len(dev_labels))\n",
    "print('Random Chance F1:', f1_score(testset_prediction_random, dev_labels))\n",
    "\n",
    "naive_bayes_classifier = NaiveBayesClassifier(num_classes=2)\n",
    "naive_bayes_classifier.fit(train_texts, train_labels)\n",
    "testset_predictions_nb = naive_bayes_classifier.predict(dev_texts)\n",
    "print('Naive Bayes F1:', f1_score(testset_predictions_nb, dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Chance F1: 0.4897959183673469\n",
      "Naive Bayes F1: 0.8627450980392156\n"
     ]
    }
   ],
   "source": [
    "### TEST SET RESULTS\n",
    "\n",
    "testset_prediction_random = predict_random(all_labels, num_samples=len(test_labels))\n",
    "print('Random Chance F1:', f1_score(testset_prediction_random, test_labels))\n",
    "\n",
    "naive_bayes_classifier = NaiveBayesClassifier(num_classes=2)\n",
    "naive_bayes_classifier.fit(all_texts, all_labels)\n",
    "testset_predictions_nb = naive_bayes_classifier.predict(test_texts)\n",
    "print('Naive Bayes F1:', f1_score(testset_predictions_nb, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression on Features \n",
    "\n",
    "Now we will be building a logistic regression based classifier on hand-engineered features.\n",
    "\n",
    "There will be implementation of the components that are required in building a Logistic Regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "final_feature_dict = defaultdict\n",
    "\n",
    "def count_words(text):\n",
    "    return np.log(len(text))\n",
    "\n",
    "def has_exclamation(text):\n",
    "    for word in text:\n",
    "        if '!' in word:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def count_positive_words(text):\n",
    "    count = 0\n",
    "    pos_file =  open('data/positive-words.txt')\n",
    "    words  = pos_file.readlines()\n",
    "    ref_word = [word.replace('\\n','') for word in words]\n",
    "    for word in text:\n",
    "        if word in ref_word:\n",
    "            count = count + 1    \n",
    "    return count\n",
    "\n",
    "def count_negative_words(text):\n",
    "    count = 0\n",
    "    neg_file = open('data/negative-words.txt')\n",
    "    words  = neg_file.readlines()\n",
    "    ref_word = [word.replace('\\n','') for word in words]\n",
    "    for word in text:\n",
    "        if word in ref_word:\n",
    "            count = count + 1    \n",
    "    return count\n",
    "\n",
    "def count_pronoun(text):\n",
    "    count = 0\n",
    "    first_pronoun = ['i', 'me' , 'my' , 'mine', 'we', 'our', 'us', 'myself', 'ourselves']\n",
    "    second_pronoun = ['you', 'your', 'yours', 'yourself', 'yourselves']\n",
    "    tot =  first_pronoun + second_pronoun\n",
    "    for word in text:\n",
    "        if word in tot:\n",
    "            count = count + 1\n",
    "    return count\n",
    "\n",
    "def extract_features(text):\n",
    "    features = []\n",
    "    \n",
    "    features.append(count_words(text))  # Number of words\n",
    "    features.append(has_exclamation(text))  # Presence of exclamation marks\n",
    "    features.append(count_positive_words(text))  # Count of positive words\n",
    "    features.append(count_negative_words(text))  # Count of negative words\n",
    "    features.append(count_pronoun(text))\n",
    "    \n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DO NOT CHANGE THE SIGNATURE OF THE function ###\n",
    "\n",
    "def featurize_data(texts, labels):\n",
    "    features = [\n",
    "        extract_features(preprocess(text)) for text in texts\n",
    "    ]\n",
    "    return torch.FloatTensor(features), torch.FloatTensor(labels)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJYAAAAnCAYAAADtl7EyAAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAlqADAAQAAAABAAAAJwAAAAA67GmEAAAE9klEQVR4Ae2cgU3sMAyGw9MbADECYgLECIgJECMgJkA3wokJECMgJkCMgJgAMQJig758eXHl5oquvZ7bXJtKqG3iOPYf107iC84t+Pr+/q5ub2+r4+PjysNQXV5eVpQJJM/Pz6H89PQ00Ok6obG45yqXha6z5vn4+BgM6PPzszYqFOb9/v6+UTYmELnKNSYGc+greCVRBK8RB1aKprrnKtdUeBxWv9EzhVCYkVG5XOU6rNGdUNo4fwqhLxNPFdDIVa4Jh+rwur6+vg5zrdwkt5CLhYnl/PFPbiBOJQ+e4eTkJHSfm8eykMuvgN3Dw8ORFd57Yczq6erqyn19fe2Fn5Wyv/HFqNbrdQD6/Py8+vn56aXL+/t7tVqtfmPfKGdAPW0nnIbK1ej4EF9wqX5gJluWD8GMwdMhQfauXl9fJ9Wnj1zRAIMeyI3HJXzywfPMH/t1ghNjFcOra2sLbbr1Im1HvfOVI+Cone6pM21UwpINUTZL5X2Kex+54seAmBXekweMR+sQN4GdhHl0ZMza2tK30MFrkmvqTcRdlQZU+WpTHhHUepDSesv3XeXCoLQhoZsYDTwxJJGbMcMZyHtbWzFQoRn9jgAIPnrHO3ZIqIgDEFI5KYDUR9DDYOgQsmOXnZoNlQsPpacj4pHoPA2FqUdK24p36yR4FyIMJMfcWRfZl07DxyIfSeqh8F4y9wInMToJd7otdNDj1XjeK64SCtIJ3KGGvb2CkykzHQYxCD1HYzzxSmIo1PEu46vbYpQYlhidhbqNlQQdWnZmoUDhmSEC0eKzy51lCFURqQ8CeChPH1xq8VR9kCu0WxEg1mJcWwkLQUEgQeBv8l6/4rEkTYHHuru765SGqBm0PLDi9HxbajaL/MrFNJe12WMpMUcAo5JVBXs6enPNvPN+HYhHLff/kSUnHJojqY2KmlxyZ00py1vuCGyENzxV+nMKPBah6e3tbYO+j4IlFPZBaya0eKo4Wd/QKK4K653dDYJSUBBIEWA3Nu68ZpU7S+Us7wWBgkBBYD4IEMqXnEBfuv7mlizzQUmwSodLSaAvXX8Zb6v70hPoS9ffxq6WnkBfuv42VuW5Mt/wt8Um0Jeuv5lhwXjpCXQL/cnCSKpv2+DN8sAqX6zFIc9tYOZSb6W/3+/s/MOAQSmaXIDUcgCq/9ntzodPNS+rZ36bLr8c2dYHg9n1gCu8ctF/VoalQQVkXPfNzY3z2QXnT2o3dIX26emJgXAMnj/FTS6U83jhTvuPjw/naep2hAFyppRzSR39wIdy4UV9H4OAfuhlqT+/kfcfhHt5eTlqww7dPT7u7OysxmuoPtm0b4v/JND9YDOZb1zxVxuU1TlQwNO0+hgU5XIKBjr+aAzIwot5DftIpMmkDJqxLiv9495YfbpH6VZjQt9CN5a+5v0wuLsk0DEUbUjwENDgiVEiPHTayKCTEy9aOejTjVldb/VsrT9yo1f2h1z3BfDQBLr2PMiEYTBIPPP1kSKSZ224mo56ubTxSZnlfSz90SH1SCl2Y+tuietg3jq8aQ8FY/FKGBheTMIM3ksMS0Ie9fyJ96N8Cs/VF5Cu+sNXdJZwp9uiL3ihM8/Qz3K7AcW6XhcXF2Gy6Q0GY6qbeeDCZNwD6vwC4Ih/bQSoTPJ9SGDiXi8IaOsNM5RDA+2hTGK76A8oYIPO4CKXtPX3UMTiRxZJ/wB1ehRLQkYoygAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling \n",
    "\n",
    "Here we are using data normalization technique to ensure the scales of the feature are consistent.\n",
    "After featurizing the dataset, we will be calling the following function before passing it to the classifier\n",
    "\n",
    "#### Normalization Formula\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(features: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    return the features transformed by the above formula of normalization\n",
    "    \"\"\"\n",
    "    min_vals = torch.min(features, dim=0, keepdim=True).values\n",
    "    max_vals = torch.max(features, dim=0, keepdim=True).values\n",
    "    normalized_features = (features - min_vals) / (max_vals - min_vals)\n",
    "    return normalized_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will be implementing the components needed to train the binary classifier using logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we define our pytorch logistic regression classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_dim: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_size = 1\n",
    "        self.coefficients = torch.nn.Linear(input_dim, self.output_size)\n",
    "        \n",
    "        initialize_weights(self.coefficients)\n",
    "        \n",
    "    def forward(self, features: torch.Tensor):\n",
    "        \n",
    "        return torch.sigmoid(self.coefficients(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the weights. \n",
    "\n",
    "Initialization of the parameters is an important step to ensure the SGD algorithm converges to a global optimum. Typically, we will try different initialization methods and compare the accuracy we achieve for the development set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(coefficients):\n",
    "    \"\"\"\n",
    "    TODO: Replace the line `raise NotImplementedError` with your code.\n",
    "    Initialize the weights of the coefficients by assigning the parameter\n",
    "    coefficients.weights.data = ...\n",
    "    \"\"\"\n",
    "    coefficients.weight.data.fill_(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Test Cases Passed!\n"
     ]
    }
   ],
   "source": [
    "test_module = torch.nn.Linear(5, 1)\n",
    "initialize_weights(test_module)\n",
    "assert test_module.weight.ravel().tolist() == [1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "\n",
    "print('All Test Cases Passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be writing the loss function by implementing binary cross-entropy loss between the prediction and label. The binary cross-entropy loss between the prediction y_hat and the target y, averaged over N examples, is:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Loss Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_loss(prediction: torch.Tensor, label: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    TODO: Implement the logistic loss function between a prediction and label.\n",
    "    \"\"\"\n",
    "    epsilon = 1e-10\n",
    "    prediction = torch.clamp(prediction, epsilon, 1 - epsilon)\n",
    "    \n",
    "    # Binary cross-entropy loss\n",
    "    loss = - (label * torch.log(prediction) + (1 - label) * torch.log(1 - prediction))\n",
    "\n",
    "    loss = torch.where(prediction == label, torch.tensor(0.0), loss)\n",
    "    \n",
    "    # Return the average loss over all samples\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "sample_input = torch.FloatTensor([[1,1],[0.0,0.0]])\n",
    "sample_target = torch.FloatTensor([[1,1],[0,0]])\n",
    "sample_output = logistic_loss(sample_input, sample_target)\n",
    "print(sample_output)\n",
    "assert sample_output.item() == 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an SGD optimizer\n",
    "\n",
    "here we will be creating the SGD optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer(model, learning_rate) -> torch.optim:\n",
    "    \"\"\"\n",
    "    Returns an Stocastic Gradient Descent Optimizer\n",
    "    \"\"\"\n",
    "    return torch.optim.SGD(model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Logits into Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, features):\n",
    "    with torch.no_grad():\n",
    "        \"\"\"\n",
    "        TODO: Replace the line `raise NotImplementedError`\n",
    "        with the logic of converting the logits into prediction labels (0, 1)\n",
    "        \"\"\"\n",
    "        logits = model(features)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs >= 0.5).float()  \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\purva31\\AppData\\Local\\Temp\\ipykernel_7232\\3005717344.py:1: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "import random\n",
    "\n",
    "\n",
    "def training_loop(\n",
    "    num_epochs,\n",
    "    batch_size,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    dev_features,\n",
    "    dev_labels,\n",
    "    optimizer,\n",
    "    model\n",
    "):\n",
    "    samples = list(zip(train_features, train_labels))\n",
    "    random.shuffle(samples)\n",
    "    batches = []\n",
    "    for i in range(0, len(samples), batch_size):\n",
    "        batches.append(samples[i:i+batch_size])\n",
    "    print(\"Training...\")\n",
    "    for i in range(num_epochs):\n",
    "        losses = []\n",
    "        for batch in tqdm(batches):\n",
    "            # Empty the dynamic computation graph\n",
    "            features, labels = zip(*batch)\n",
    "            features = torch.stack(features)\n",
    "            labels = torch.stack(labels)\n",
    "            optimizer.zero_grad()\n",
    "            # Run the model\n",
    "            logits = model(features)\n",
    "            # Compute loss\n",
    "            loss = logistic_loss(torch.squeeze(logits), labels)\n",
    "            # In this logistic regression example,\n",
    "            # this entails computing a single gradient\n",
    "            loss.backward()\n",
    "            # Backpropogate the loss through our model\n",
    "            \n",
    "            # Update our coefficients in the direction of the gradient.\n",
    "            optimizer.step()\n",
    "             # For logging\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "        # Estimate the f1 score for the development set\n",
    "        dev_f1 = f1_score(predict(model, dev_features), dev_labels)\n",
    "        print(f\"epoch {i}, loss: {sum(losses)/len(losses)}\")\n",
    "        print(f\"Dev F1 {dev_f1}\")\n",
    "        \n",
    "    # Return the trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the classifier \n",
    "\n",
    "Here we are training a logistic regressor on your hand-engineered features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a546b015b97e41bdb08a3739cfd9ed9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 0.9311507046222687\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80578a5db5f04a6b8c6c93f647a16825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 0.9196842432022094\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e535c0b66e684303a167ff12fb2876bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss: 0.9086977541446686\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b67ce2fd2d4ed9b247bea6e53f31f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, loss: 0.8981788575649261\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5497270638304a98ba35b5dc74670238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, loss: 0.888114583492279\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8c3edae6f64365a9dfeb1903432ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, loss: 0.8784917175769806\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a1b90d95a64a9d83ae3dd21aafc3f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, loss: 0.8692965090274811\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa784553fb69463089903922fa131c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, loss: 0.8605150282382965\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c81a1b77f4426ea9ede0fac2427f15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, loss: 0.8521331310272217\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463260a9393c44bab7289905ac7906f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, loss: 0.8441366493701935\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050acf27fee74b5d8c81a2e3642bf5c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, loss: 0.8365112245082855\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdfa90cdcde84687982d5805dc7caa83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, loss: 0.8292425036430359\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e010248be3c4e02bfda67f3dcb2f673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, loss: 0.8223163902759552\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49571900bcd4a308d08df0e79df684d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, loss: 0.8157185673713684\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91417bc7092a48f78a45c2e5a7b1f2a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, loss: 0.8094351828098297\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e857dc049ccc44888ad0f29243732ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, loss: 0.8034524500370026\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c644d9f0ec8a4c7bb6ee472eeb4bcbca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16, loss: 0.7977568566799164\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2fe2e3486341d783234ee65cbbc34a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17, loss: 0.7923351407051087\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d2759490cd45bf80c1301ced120933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18, loss: 0.7871743142604828\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37f21e0fe924861bf1d36ee9bce35c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19, loss: 0.7822618365287781\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4a6eb36d0c4133b1ab60a5dae21e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, loss: 0.7775854349136353\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382130bcc14c4966a626025949814b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21, loss: 0.7731332361698151\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9dde9444040456e849d30077b6469d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22, loss: 0.7688938081264496\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f077e2434a45c486ecc193a97cfdf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23, loss: 0.7648559987545014\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469b45dd982443e8a196bc1bdcf6f197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24, loss: 0.7610092163085938\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f5c69118664f34947511a067d8448b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25, loss: 0.7573431193828583\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c08dbb45302147b988c7945b3254113a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26, loss: 0.7538479268550873\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b74969316434e11ba57b7ce4aa95d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, loss: 0.7505141735076905\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12902ef07e9f42569851d4670f509aaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28, loss: 0.7473328649997711\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c91fa87eecc84f44ab16c8cf70201e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29, loss: 0.7442953526973725\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1822e2f210874797bff7af9a0209ce79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30, loss: 0.7413934767246246\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd0526f44e84492a9fb4b7b2ff610d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31, loss: 0.7386193871498108\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93cae992ea264b94b2f913b684d6b37d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32, loss: 0.7359656512737274\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918f39e58b7e48448f85d614d5c83675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, loss: 0.7334252178668976\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b674fa012133407f9cb8009cee11c61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34, loss: 0.7309913992881775\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a162b012ef824e299bb087cc5a5d10ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35, loss: 0.7286577999591828\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb24bc2388441ec916e6d3e1d6d34e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36, loss: 0.7264184594154358\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "989cafde47014530b4a7ed92bdfa25f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37, loss: 0.7242676436901092\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3525c55875c34b8fa4f59978c78c7e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38, loss: 0.7222001075744628\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f38789a99c143d98cac6a864024e11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39, loss: 0.7202106237411499\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60062bf5a2fa426d806023089313e818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, loss: 0.7182945430278778\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f9d24457c64d789075e92eece01cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41, loss: 0.7164472997188568\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680c0a0cdccf4a6791eb8a660993794d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42, loss: 0.7146647036075592\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbaff35c5eac473694df57fb233d6cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43, loss: 0.7129427134990692\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97d28a5066a4333a7e4f8cb935374ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44, loss: 0.7112775981426239\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec61baa15b047bea51a338209d77069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45, loss: 0.7096659004688263\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea257f19defb4eb58debdcad4c78cf8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46, loss: 0.7081041812896729\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38050acd07e845ee886746ea75294f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, loss: 0.7065894544124603\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61bb40917fc48e6b611a81240a49362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48, loss: 0.7051187753677368\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f0c5def6b541af9a7c6e176c35965f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49, loss: 0.7036894142627717\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8383aa16eeb84e999b1fa38a8c8fa0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50, loss: 0.7022987902164459\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f243aa38e24a4ca6b78a060c1155e56f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51, loss: 0.7009445250034332\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef754cb376f147a1b97da36dd54e79ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52, loss: 0.6996244192123413\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6bf4da78d24b3cbecbcfba06240aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53, loss: 0.6983363270759583\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d5026933ac24105974d66e291e88c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54, loss: 0.6970782697200775\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e34728540f34240a907a8ecadfdc94d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55, loss: 0.6958484590053559\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23572696feca48e8af689b97294fe9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56, loss: 0.6946451842784882\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a487e2ea73b34fcd81fd62e8162dd8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57, loss: 0.6934667646884918\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b48df19c1f74df6a260a5a2414b693f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58, loss: 0.692311805486679\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b7150d2bc024169a93a9f4e9884efed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59, loss: 0.6911788940429687\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1bb30eba44545318282c8bfe6bfc22e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60, loss: 0.690066659450531\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c21e6a5c30f94b299ca68a0ce1e4925a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61, loss: 0.6889739215373993\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6efc34055245c1a9ebd68c6bb11c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62, loss: 0.6878995299339294\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2534260a255e427aa82ed6a846b76353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63, loss: 0.6868424832820892\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "825252eb64804000b5772d7cd886153d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64, loss: 0.6858016788959503\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256fb14352724d8791ad1b2aec06f45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65, loss: 0.6847763180732727\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e7e65b011b43e7b449a3ea2aee5f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66, loss: 0.6837655007839203\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eaf13e4ad96427ea82010051afad8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67, loss: 0.6827683448791504\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07012e6304dc4b40a1b213b737467f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68, loss: 0.6817842066287995\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5da03f79e504889886e3a7a38c81b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69, loss: 0.6808123409748077\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2670e12a5f0e4933b7628bea9657c2df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70, loss: 0.6798521101474762\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3bb799074114e63a2962510b406ac8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71, loss: 0.6789029121398926\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8ac33daad1479a8ade11383945386a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72, loss: 0.6779641568660736\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9967e063304525afe4cbc1b67194d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 73, loss: 0.6770353257656098\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a3dcc192b849139bdc05a70f1c5fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74, loss: 0.6761159598827362\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d787ff36d01244f89b4bfd09e1c37b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75, loss: 0.6752055943012237\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92904fd1e21487d917d4e5821eb92cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76, loss: 0.6743037939071655\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02126b0c376f4ed7a43a7216101f0493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77, loss: 0.673410153388977\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6ca8dfa8164ea8b31e1b418b77b3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78, loss: 0.6725243210792542\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240444a5396e4c2d9ced19f53ce76cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 79, loss: 0.671645975112915\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a96785a97641c5a3c30c58e21e1945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80, loss: 0.6707746922969818\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "852f08b151b8499697e08e94e51fb67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81, loss: 0.6699102878570556\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492143449bd24c87aded82ead455675a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82, loss: 0.6690524399280549\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84df1d6cbb64e939940064c092abc8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83, loss: 0.6682008922100067\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a96b5f41ac94fec935179f10875b0c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84, loss: 0.6673553884029388\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db72752425a44cf9f0ea24219de280a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85, loss: 0.666515725851059\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32014af30de74fd48902d5453fbe4323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86, loss: 0.665681678056717\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3acbcf251f97419aa44a673446c848c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87, loss: 0.6648530721664428\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3dbbebfa2a04bb0bbee3d7043dbd43a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88, loss: 0.6640296876430511\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3620aa4bd35e447493c6b775458a66bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89, loss: 0.6632113873958587\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588a0133d3f94f22ad51bb70128d587c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90, loss: 0.662397974729538\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee2f224671d48108ea869bed3466841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91, loss: 0.661589378118515\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df3f65fbbae04f5891d4ce89321c84cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92, loss: 0.6607853412628174\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b188259471648aab345db01cb330bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93, loss: 0.6599858224391937\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2555330afb134d409f633df3ebdd6e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94, loss: 0.6591906726360321\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55b56729a1444d6af902a2d5ed9e81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95, loss: 0.6583997547626496\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2020e61e04469fbe1d607328f4d1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96, loss: 0.6576130330562592\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2993c882e64865a78fb8d2af85531d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97, loss: 0.6568303167819977\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea1f6977d3142158b8ddca90f1e81fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98, loss: 0.6560515999794007\n",
      "Dev F1 0.5769230769230769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817862ec94b14b35904299fae3807a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99, loss: 0.6552767038345337\n",
      "Dev F1 0.5769230769230769\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "train_features, train_labels_tensor = featurize_data(train_texts, train_labels)\n",
    "train_features = normalize(train_features)\n",
    "dev_features, dev_labels_tensor = featurize_data(dev_texts, dev_labels)\n",
    "dev_features = normalize(dev_features)\n",
    "model = SentimentClassifier(train_features.shape[1]) \n",
    "optimizer = make_optimizer(model, learning_rate=0.01)\n",
    "\n",
    "trained_model = training_loop(\n",
    "    num_epochs,\n",
    "    16,\n",
    "    train_features,\n",
    "    train_labels_tensor,\n",
    "    dev_features,\n",
    "    dev_labels_tensor,\n",
    "    optimizer,\n",
    "    model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the predictions on the Test Set using the Trained model and printing the F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Chance F1: 0.6111111111111113\n",
      "All Test Cases Passed!\n"
     ]
    }
   ],
   "source": [
    "### DEV SET RESULTS\n",
    "\n",
    "train_texts, train_labels, dev_texts, dev_labels = split_dataset(all_texts, all_labels)\n",
    "\n",
    "devset_prediction_random = predict_random(train_labels, num_samples=len(dev_labels))\n",
    "dev_random_f1 = f1_score(devset_prediction_random, dev_labels)\n",
    "print('Random Chance F1:', dev_random_f1)\n",
    "\n",
    "assert dev_random_f1 > 0\n",
    "\n",
    "print('All Test Cases Passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "Accuracy: 0.5135135135135135\n",
      "F1-score 0.6785714285714285\n"
     ]
    }
   ],
   "source": [
    "### DEV SET RESULTS - LOGISTIC REGRESSION\n",
    "\n",
    "dev_features, dev_labels = featurize_data(dev_texts, dev_labels)\n",
    "dev_features = normalize(dev_features)\n",
    "dev_logistic_accuracy = accuracy(predict(trained_model, dev_features), dev_labels.tolist())\n",
    "dev_logistic_f1 = f1_score(predict(trained_model, dev_features), dev_labels.tolist())\n",
    "print('Logistic Regression Results:')\n",
    "print('Accuracy:', dev_logistic_accuracy)\n",
    "print('F1-score', dev_logistic_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Chance F1: 0.4615384615384615\n",
      "Naive Bayes F1: 0.8627450980392156\n"
     ]
    }
   ],
   "source": [
    "### TEST SET RESULTS - RANDOM CHANCE\n",
    "\n",
    "# load the test data\n",
    "test_datapath = \"data/testset.txt\"\n",
    "test_texts, test_labels = load_test_data(test_datapath)\n",
    "\n",
    "testset_prediction_random = predict_random(all_labels, num_samples=len(test_labels))\n",
    "test_random_f1 = f1_score(testset_prediction_random, test_labels)\n",
    "print('Random Chance F1:', test_random_f1)\n",
    "testset_prediction_naive = naive_bayes_classifier.predict(test_texts)\n",
    "test_naive_f1 = f1_score(testset_prediction_naive, test_labels)\n",
    "print('Naive Bayes F1:', test_naive_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "Accuracy: 0.5\n",
      "F1-score 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "### TEST SET RESULTS\n",
    "\n",
    "# load the test data\n",
    "test_datapath = \"data/testset.txt\"\n",
    "test_texts, test_labels = load_test_data(test_datapath)\n",
    "\n",
    "test_features, test_labels = featurize_data(test_texts, test_labels)\n",
    "test_features = normalize(test_features)\n",
    "test_logistic_accuracy = accuracy(predict(trained_model, test_features), test_labels.tolist())\n",
    "test_logistic_f1 = f1_score(predict(trained_model, test_features), test_labels.tolist())\n",
    "print('Logistic Regression Results:')\n",
    "print('Accuracy:', test_logistic_accuracy)\n",
    "print('F1-score', test_logistic_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
